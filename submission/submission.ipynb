{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import joblib\n",
    "from joblib import Parallel\n",
    "from joblib import delayed\n",
    "import lightgbm as lgb\n",
    "import lightgbm\n",
    "import optuna.integration.lightgbm as lgb\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from abc import ABCMeta, abstractmethod\n",
    "from scipy.stats import median_absolute_deviation\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm\n",
    "from typing import Callable, List, Tuple, Union, Optional, Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../input/optiver-realized-volatility-prediction/'\n",
    "\n",
    "def read_book(train_test: str, stock_id: int):\n",
    "    if stock_id is None:\n",
    "        return pd.concat(read_book(train_test, i) for i in range(127))\n",
    "\n",
    "    book = pd.read_parquet(DATA_DIR + f\"book_{train_test}.parquet/stock_id={stock_id}\")\n",
    "    book[\"stock_id\"] = stock_id\n",
    "    return book\n",
    "\n",
    "\n",
    "def read_trade(train_test: str, stock_id: int):\n",
    "    if stock_id is None:\n",
    "        return pd.concat(read_trade(train_test, i) for i in range(127))\n",
    "\n",
    "    trade = pd.read_parquet(DATA_DIR + f\"trade_{train_test}.parquet/stock_id={stock_id}\")\n",
    "    trade[\"stock_id\"] = stock_id\n",
    "    return trade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to compute features from book\n",
    "\n",
    "\n",
    "def stock_id(book: pd.DataFrame) -> pd.Series:\n",
    "    return book.stock_id.groupby(book.time_id).first()\n",
    "\n",
    "\n",
    "def time_id(book: pd.DataFrame) -> pd.Series:\n",
    "    return book.time_id.groupby(book.time_id).first()\n",
    "\n",
    "\n",
    "def wap(book: pd.DataFrame) -> pd.Series:\n",
    "    return (\n",
    "        book[\"bid_price1\"] * book[\"ask_size1\"] + book[\"ask_price1\"] * book[\"bid_size1\"]\n",
    "    ) / (book[\"bid_size1\"] + book[\"ask_size1\"])\n",
    "\n",
    "\n",
    "def wap2(book: pd.DataFrame) -> pd.Series:\n",
    "    return (\n",
    "        book[\"bid_price2\"] * book[\"ask_size2\"] + book[\"ask_price2\"] * book[\"bid_size2\"]\n",
    "    ) / (book[\"bid_size2\"] + book[\"ask_size2\"])\n",
    "\n",
    "\n",
    "def wap3(book: pd.DataFrame) -> pd.Series:\n",
    "    return (\n",
    "        book[\"bid_price1\"] * book[\"bid_size1\"] + book[\"ask_price1\"] * book[\"ask_size1\"]\n",
    "    ) / (book[\"bid_size1\"] + book[\"ask_size1\"])\n",
    "\n",
    "\n",
    "def wap4(book: pd.DataFrame) -> pd.Series:\n",
    "    return (\n",
    "        book[\"bid_price2\"] * book[\"bid_size2\"] + book[\"ask_price2\"] * book[\"ask_size2\"]\n",
    "    ) / (book[\"bid_size2\"] + book[\"ask_size2\"])\n",
    "\n",
    "\n",
    "def price_spread1(book: pd.DataFrame) -> pd.Series:\n",
    "    return book[\"ask_price1\"] - book[\"bid_price1\"]\n",
    "\n",
    "\n",
    "def price_spread2(book: pd.DataFrame) -> pd.Series:\n",
    "    return book[\"ask_price2\"] - book[\"bid_price2\"]\n",
    "\n",
    "\n",
    "def price_spread_bid(book: pd.DataFrame) -> pd.Series:\n",
    "    return book[\"bid_price1\"] - book[\"bid_price2\"]\n",
    "\n",
    "\n",
    "def price_spread_ask(book: pd.DataFrame) -> pd.Series:\n",
    "    return book[\"ask_price1\"] - book[\"ask_price2\"]\n",
    "\n",
    "\n",
    "def size_total_bid(book: pd.DataFrame) -> pd.Series:\n",
    "    return book['bid_size1'] + book['bid_size2']\n",
    "\n",
    "\n",
    "def size_total_ask(book: pd.DataFrame) -> pd.Series:\n",
    "    return book['ask_size1'] + book['ask_size2']\n",
    "\n",
    "\n",
    "def size_total1(book: pd.DataFrame) -> pd.Series:\n",
    "    return book['bid_size1'] + book['ask_size1']\n",
    "\n",
    "\n",
    "def size_total2(book: pd.DataFrame) -> pd.Series:\n",
    "    return book['bid_size2'] + book['ask_size2']\n",
    "\n",
    "\n",
    "def size_total3(book: pd.DataFrame) -> pd.Series:\n",
    "    return book['bid_size1'] + book['bid_size2'] + book['ask_size1'] + book['ask_size2']\n",
    "\n",
    "\n",
    "def size_spread1(book: pd.DataFrame) -> pd.Series:\n",
    "    return book['bid_size1'] - book['ask_size1']\n",
    "\n",
    "\n",
    "def size_spread2(book: pd.DataFrame) -> pd.Series:\n",
    "    return book['bid_size2'] - book['ask_size2']\n",
    "\n",
    "\n",
    "def size_spread3(book: pd.DataFrame) -> pd.Series:\n",
    "    return book['bid_size1'] + book['bid_size2'] - book['ask_size1'] - book['ask_size2']\n",
    "\n",
    "\n",
    "def log_return(book: pd.DataFrame) -> pd.Series:\n",
    "    return wap(book).apply(np.log).groupby(book.time_id).pipe(lambda ser: ser.diff()).fillna(0)\n",
    "\n",
    "\n",
    "def log_return2(book: pd.DataFrame) -> pd.Series:\n",
    "    return wap2(book).apply(np.log).groupby(book.time_id).pipe(lambda ser: ser.diff()).fillna(0)\n",
    "\n",
    "\n",
    "def log_return3(book: pd.DataFrame) -> pd.Series:\n",
    "    return wap3(book).apply(np.log).groupby(book.time_id).pipe(lambda ser: ser.diff()).fillna(0)\n",
    "\n",
    "\n",
    "def log_return4(book: pd.DataFrame) -> pd.Series:\n",
    "    return wap4(book).apply(np.log).groupby(book.time_id).pipe(lambda ser: ser.diff()).fillna(0)\n",
    "\n",
    "\n",
    "def instvar(book: pd.DataFrame):\n",
    "    \"\"\"Compute instantaneous variance.\"\"\"\n",
    "    return log_return(book) ** 2\n",
    "\n",
    "\n",
    "def instvar2(book: pd.DataFrame):\n",
    "    \"\"\"Compute instantaneous variance.\"\"\"\n",
    "    return log_return2(book) ** 2\n",
    "\n",
    "\n",
    "def instvar3(book: pd.DataFrame):\n",
    "    \"\"\"Compute instantaneous variance.\"\"\"\n",
    "    return log_return3(book) ** 2\n",
    "\n",
    "\n",
    "def instvar4(book: pd.DataFrame):\n",
    "    \"\"\"Compute instantaneous variance.\"\"\"\n",
    "    return log_return4(book) ** 2\n",
    "\n",
    "\n",
    "def voldiff(book):\n",
    "    return instvar(book).loc[book.seconds_in_bucket<300].groupby(book.time_id).agg(np.linalg.norm) - instvar(book).loc[book.seconds_in_bucket>=300].groupby(book.time_id).agg(np.linalg.norm)\n",
    "\n",
    "\n",
    "def voldiff2(book):\n",
    "    return instvar2(book).loc[book.seconds_in_bucket<300].groupby(book.time_id).agg(np.linalg.norm) - instvar2(book).loc[book.seconds_in_bucket>=300].groupby(book.time_id).agg(np.linalg.norm)\n",
    "\n",
    "\n",
    "def voldiff3(book):\n",
    "    return instvar3(book).loc[book.seconds_in_bucket<300].groupby(book.time_id).agg(np.linalg.norm) - instvar3(book).loc[book.seconds_in_bucket>=300].groupby(book.time_id).agg(np.linalg.norm)\n",
    "\n",
    "\n",
    "def voldiff4(book):\n",
    "    return instvar4(book).loc[book.seconds_in_bucket<300].groupby(book.time_id).agg(np.linalg.norm) - instvar4(book).loc[book.seconds_in_bucket>=300].groupby(book.time_id).agg(np.linalg.norm)\n",
    "\n",
    "\n",
    "def updown(book: pd.DataFrame) -> pd.Series:\n",
    "    n_samples = 10\n",
    "    wap_groupby = wap(book).groupby(book.time_id)\n",
    "    head = wap_groupby.head(n_samples).groupby(book.time_id).mean()\n",
    "    tail = wap_groupby.tail(n_samples).groupby(book.time_id).mean()\n",
    "    return (tail - head).apply(np.sign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to compute features from trade\n",
    "\n",
    "def trade__size(trade: pd.DataFrame) -> pd.Series:\n",
    "    return trade['size']\n",
    "\n",
    "\n",
    "def trade__price(trade: pd.DataFrame) -> pd.Series:\n",
    "    return trade['price']\n",
    "\n",
    "\n",
    "def trade__order_count(trade: pd.DataFrame) -> pd.Series:\n",
    "    return trade['order_count']\n",
    "\n",
    "\n",
    "def trade__true_range(trade: pd.DataFrame) -> pd.Series:\n",
    "    return trade['price'].groupby(trade.time_id).max() - trade['price'].groupby(trade.time_id).min()\n",
    "\n",
    "\n",
    "def trade__seconds_in_bucket_count(trade: pd.DataFrame) -> pd.Series:\n",
    "    return trade['seconds_in_bucket'].groupby(trade.time_id).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "\n",
    "def derive(fn: Callable, name=None, **kwargs) -> Callable:\n",
    "    \"\"\"Derive a function,named name,which when called will behave like\n",
    "    fn called with the keyword arguments kwargs.\n",
    "    \"\"\"\n",
    "    function = partial(fn, **kwargs)\n",
    "    if name is not None:\n",
    "        function.__name__ = name\n",
    "    return function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregation Functions\n",
    "\n",
    "\n",
    "def ewm(series: pd.Series, halflife: float = 10.0) -> pd.Series:\n",
    "    return series.ewm(halflife=halflife).mean().iat[-1]\n",
    "\n",
    "\n",
    "ewm10 = derive(ewm, \"ewm10\", halflife=10.0)\n",
    "ewm20 = derive(ewm, \"ewm20\", halflife=20.0)\n",
    "ewm30 = derive(ewm, \"ewm30\", halflife=30.0)\n",
    "ewm40 = derive(ewm, \"ewm40\", halflife=40.0)\n",
    "ewm50 = derive(ewm, \"ewm50\", halflife=50.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "class CreateFeatures:\n",
    "    \"\"\"Class to compute features.\n",
    "\n",
    "    Args:\n",
    "        features: list[dict[str, (Callable, Callable)]]\n",
    "            Each key is the name of a feature.\n",
    "            Each value is a tuple: ``(fn, agg)`` where fn is a function applied to the book \n",
    "            to make series and agg is an aggregation function\n",
    "\n",
    "            If agg is not None:\n",
    "                feature (pd.Series) will be computed by 1) applying fn to a book,\n",
    "                2) aggregating the output by `time_id`, and then \n",
    "                3) aggregate the groupby object with agg.\n",
    "                fn receives pd.DataFrame of book and returns pd.Series of feature time-series.\n",
    "                agg is any aggregation function that can be passed to pd.SeriesGroupby.agg.\n",
    "\n",
    "            If agg is None:\n",
    "                feature will be computed by fn(book).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, features: List[Tuple[Callable, Callable]]) -> None:\n",
    "        # attribute _features is:\n",
    "        # each key: name of feature \"{fn name}__{aggregation name}\"\n",
    "        # each value: (fn, agg) \n",
    "        self.__features = OrderedDict()\n",
    "        for fn, agg in features:\n",
    "            name = self.__feature_name(fn, agg)\n",
    "            self.register_feature(name, fn=fn, agg=agg)\n",
    "\n",
    "    def compute_df_features(self, book, trade) -> pd.DataFrame:\n",
    "        return pd.merge(\n",
    "                        pd.DataFrame(\n",
    "                        {\n",
    "                            name: self.__compute_feature(book, fn, agg)\n",
    "                            for name, fn, agg in self.features()\n",
    "                            if not 'trade__' in name\n",
    "                        }\n",
    "                        ).reset_index(drop=True),\n",
    "                        pd.DataFrame(\n",
    "                        {\n",
    "                            name: self.__compute_feature(trade, fn, agg)\n",
    "                            for name, fn, agg in self.features()\n",
    "                            if \"trade__\" in name or \"stock_id\" in name or \"time_id\" in name\n",
    "                        }\n",
    "                        ).reset_index(drop=True),\n",
    "                        on=[\"stock_id\", \"time_id\"],\n",
    "                        how=\"outer\"\n",
    "        )\n",
    "\n",
    "    def register_feature(self, name, fn, agg) -> None:\n",
    "        \"\"\"Adds a feature to the class.\"\"\"\n",
    "        self.__features[name] = (fn, agg)\n",
    "\n",
    "    def features(self) -> Iterable:\n",
    "        \"\"\"Returns an iterator over (name, fn, agg) of features.\"\"\"\n",
    "        for name, (fn, agg) in self.__features.items():\n",
    "            yield (name, fn, agg)\n",
    "\n",
    "    @property\n",
    "    def feature_names(self) -> List[str]:\n",
    "        return list(self.__features.keys())\n",
    "\n",
    "    def __feature_name(self, fn, agg) -> str:\n",
    "        name = fn.__name__\n",
    "        if agg is not None:\n",
    "            name += \"__\" + (agg if isinstance(agg, str) else agg.__name__)\n",
    "        return name\n",
    "\n",
    "    def __compute_feature(self, book_trade, fn, agg) -> pd.Series:\n",
    "        output = fn(book_trade)\n",
    "        if agg is not None:\n",
    "            output = output.groupby(book_trade.time_id).agg(agg)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "features = [\n",
    "    # book\n",
    "    (stock_id, None),\n",
    "    (time_id, None),\n",
    "    (instvar, np.linalg.norm),  # volatility\n",
    "    (instvar2, np.linalg.norm),\n",
    "    (instvar3, np.linalg.norm),\n",
    "    (instvar4, np.linalg.norm),\n",
    "    (voldiff, None),\n",
    "    (voldiff2, None),\n",
    "    (voldiff3, None),\n",
    "    (voldiff4, None),\n",
    "    (updown, None),\n",
    "    # trade\n",
    "    (trade__true_range, None),\n",
    "    (trade__seconds_in_bucket_count, None),\n",
    "]\n",
    "\n",
    "fns = [\n",
    "    # book\n",
    "    price_spread1, price_spread2, price_spread_bid, price_spread_ask,\n",
    "    size_total_bid, size_total_ask, size_total1, size_total2, size_total3, size_spread1, size_spread2, size_spread3,\n",
    "\n",
    "    # trade\n",
    "    trade__size,\n",
    "    trade__price, trade__order_count,\n",
    "    ]\n",
    "aggs = [np.mean, np.max, np.min, median_absolute_deviation, np.std,\n",
    "        ewm10, ewm20, ewm30, ewm40, ewm50]\n",
    "\n",
    "for fn, agg in product(fns, aggs):\n",
    "    features.append((fn, agg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = CreateFeatures(features)\n",
    "\n",
    "cf.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_df_features(path):\n",
    "    book = pd.read_parquet(path)\n",
    "    trade = pd.read_parquet(path.replace(\"book\", \"trade\"))\n",
    "    book[\"stock_id\"] = trade[\"stock_id\"] = int(path.split(\"=\")[-1])\n",
    "    return cf.compute_df_features(book, trade)\n",
    "\n",
    "\n",
    "def create_df_features(cf: CreateFeatures, train_test: str = None, n_jobs=-1) -> pd.DataFrame:\n",
    "    # n_jobs (int, default=1): The maximum number of concurrently running jobs. If -1 all CPUs are used.\n",
    "    paths = glob.glob(DATA_DIR + f\"book_{train_test}.parquet/*\")\n",
    "    dfs = Parallel(n_jobs=n_jobs)(delayed(_compute_df_features)(path) for path in tqdm(paths))\n",
    "    df_features = pd.concat(dfs).reset_index(drop=True)\n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(metaclass=ABCMeta):\n",
    "\n",
    "    def __init__(self, run_fold_name: str, feature_names: List[str],\n",
    "                 params: dict) -> None:\n",
    "        ''' Constructor\n",
    "\n",
    "        :param feature_names: list of feature names to specify columns of feature dataframe\n",
    "        :param params: hyper parameters\n",
    "        '''\n",
    "        self.run_fold_name = run_fold_name\n",
    "        self.feature_names = feature_names\n",
    "        self.params = params\n",
    "        self.model = None\n",
    "\n",
    "    @abstractmethod\n",
    "    def train(self, X_train: pd.DataFrame, y_train: pd.Series,\n",
    "              X_valid: Optional[pd.DataFrame] = None,\n",
    "              y_valid: Optional[pd.Series] = None\n",
    "              ) -> None:\n",
    "        ''' trains a model\n",
    "\n",
    "        :param X_train: features of training data\n",
    "        :param y_train: targets of training data\n",
    "        :param X_valid: features of validation data\n",
    "        :param y_valid: targets of validation data\n",
    "        '''\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict(self, X: pd.DataFrame) -> np.array:\n",
    "        ''' returns prediction output from a learned model\n",
    "\n",
    "        :param X: features of test data or validation data\n",
    "        :return: predicted value\n",
    "        '''\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def save_model(self) -> None:\n",
    "        ''' saves a model '''\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def load_model(self) -> None:\n",
    "        ''' loads a model '''\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelLGB(Model):\n",
    "\n",
    "\n",
    "    def train(self, X_train, y_train, X_valid=None, y_valid=None):\n",
    "\n",
    "        params = self.params\n",
    "        best_params, tuning_history = dict(), list()\n",
    "        if X_valid is not None:\n",
    "            # weights to change feval from RMSE to RMSPE\n",
    "            # idea from: https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/250324\n",
    "            w_train = 1/np.square(y_train)\n",
    "            w_valid = 1/np.square(y_valid)\n",
    "            lgb_train = lgb.Dataset(X_train, y_train, weight=w_train)\n",
    "            lgb_eval = lgb.Dataset(X_valid, y_valid, weight=w_valid)\n",
    "            self.model = lgb.train(params,\n",
    "                                   lgb_train,\n",
    "                                   valid_sets=lgb_eval,\n",
    "                                   feval=rmspe,\n",
    "                                   verbose_eval=100,\n",
    "                                   early_stopping_rounds=100,\n",
    "                                   categorical_feature=['stock_id'],\n",
    "                                )\n",
    "        else:\n",
    "            w_train = 1/np.square(y_train)\n",
    "            lgb_train = lgb.Dataset(X_train, y_train, weight=w_train)\n",
    "            self.model = lgb.train(params,\n",
    "                                   lgb_train,\n",
    "                                   num_boost_round=100,\n",
    "                                   feval=rmspe,\n",
    "                                   categorical_feature=['stock_id'],\n",
    "                           )\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        return self.model.predict(X_test)\n",
    "\n",
    "    def save_model(self):\n",
    "        self.model.save_model('model.txt')\n",
    "\n",
    "    def load_model(self):\n",
    "        self.model = lgb.Booster(model_file='model.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delf-defiend evaluation metric function\n",
    "def rmspe(y_true: np.array, y_pred: np.array):\n",
    "    ''' self-defined eval metric\n",
    "        Root Mean Squared Percentage Error\n",
    "\n",
    "    :return: name: str, eval_result: float, is_higher_better: bool\n",
    "    '''\n",
    "    if type(y_pred) == lightgbm.basic.Dataset:\n",
    "        y_pred = y_pred.get_label()\n",
    "    rmspe = np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
    "    return 'RMSPE', rmspe, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Util:\n",
    "    @classmethod\n",
    "    def dump(cls, value, path):\n",
    "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "        joblib.dump(value, path, compress=True)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, path):\n",
    "        return joblib.load(path)\n",
    "\n",
    "    @classmethod\n",
    "    def submission(cls, df_pred: pd.DataFrame) -> None:\n",
    "        row_id = df_pred['stock_id'].apply(str) + '-' + df_pred['time_id'].apply(str)\n",
    "        df_submission = pd.DataFrame({'row_id': row_id, 'target':df_pred['target']})\n",
    "        df_submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Runner:\n",
    "\n",
    "    def __init__(self, run_name: str, model_cls: Callable[[str, dict], Model],\n",
    "                 feature_names: List[str], df_features_train: pd.DataFrame,\n",
    "                 df_features_test: pd.DataFrame, params: dict):\n",
    "        ''' Constructor\n",
    "\n",
    "        :param run_name: name of run\n",
    "        :param model_cls: class of model\n",
    "        :param feature_names: list of feature names\n",
    "        :param params: hyper parameters\n",
    "        '''\n",
    "        self.run_name = run_name\n",
    "        self.model_cls = model_cls\n",
    "        self.feature_names = feature_names\n",
    "        self.X_train_all = df_features_train\n",
    "        self.X_test = df_features_test\n",
    "        self.params = params\n",
    "        self.n_fold = 4\n",
    "\n",
    "    def __train_fold(self, i_fold: Union[int, str]) -> Tuple[\n",
    "                    Model, Optional[np.array],\n",
    "                    Optional[np.array], Optional[float]]:\n",
    "        ''' specifies number of fold for cv then learns & evaluates\n",
    "\n",
    "        :param i_fold: number of fold ('all' for all)\n",
    "        :return: a tuple of instance of model, index of record,\n",
    "                 predicted value, and evaluation score\n",
    "                 (returns only model if i_fold=='all')\n",
    "        '''\n",
    "        # load train data\n",
    "        y_train_all = self.__load_y_train()\n",
    "        self.X_train_all['stock_id'] = self.X_train_all['stock_id'].astype('int64')\n",
    "        self.X_train_all['time_id'] = self.X_train_all['time_id'].astype('int64')\n",
    "        Xy_train_all = pd.merge(self.X_train_all, y_train_all,\n",
    "                                left_on=['stock_id','time_id'], right_on=['stock_id','time_id'],\n",
    "                                how='inner')\n",
    "        X_train_all = Xy_train_all[self.feature_names]\n",
    "        y_train_all = Xy_train_all['target']\n",
    "\n",
    "        validation = i_fold != 'all'\n",
    "        if validation:\n",
    "            # split data into training and validation\n",
    "            idx_train, idx_valid = self.__load_index_fold(i_fold)\n",
    "            X_train = X_train_all.iloc[idx_train]\n",
    "            y_train = y_train_all.iloc[idx_train]\n",
    "            X_valid = X_train_all.iloc[idx_valid]\n",
    "            y_valid = y_train_all.iloc[idx_valid]\n",
    "\n",
    "            # execute learning\n",
    "            model = self.__build_model(i_fold)\n",
    "            model.train(X_train, y_train, X_valid, y_valid)\n",
    "\n",
    "            # prediction and evaluation with validation data\n",
    "            pred_valid = model.predict(X_valid)\n",
    "            _, score, _ = rmspe(y_true=y_valid, y_pred=pred_valid)\n",
    "\n",
    "            # return model, index, prediction, and score\n",
    "            return model, idx_valid, pred_valid, score\n",
    "        else:\n",
    "            # learining with all data\n",
    "            model = self.__build_model(i_fold)\n",
    "            model.train(X_train_all, y_train_all)\n",
    "\n",
    "            # return model\n",
    "            return model, None, None, None\n",
    "\n",
    "    def run_train_cv(self) -> None:\n",
    "        ''' learns and evaluates by CV\n",
    "\n",
    "        learns, evaluates, and saves models and scores of each fold\n",
    "        '''\n",
    "        scores = []\n",
    "        idxes_valid = []\n",
    "        preds = []\n",
    "\n",
    "        # learning for each fold\n",
    "        for i_fold in range(self.n_fold):\n",
    "            model, idx_valid, pred_valid, score = self.__train_fold(i_fold)\n",
    "\n",
    "            # hold result\n",
    "            idxes_valid.append(idx_valid)\n",
    "            scores.append(score)\n",
    "            preds.append(pred_valid)\n",
    "\n",
    "            # save model\n",
    "            model.save_model()\n",
    "        print(f'Mean score of the folds: {np.mean(scores)}')\n",
    "\n",
    "    def run_predict_cv(self) -> pd.DataFrame:\n",
    "        ''' predicts for test data with the mean of\n",
    "            each fold's model learned through CV\n",
    "            \n",
    "            :return: predicted target as the mean of folds\n",
    "        '''\n",
    "        preds = []\n",
    "        # prediction for each fold's model\n",
    "        for i_fold in range(self.n_fold):\n",
    "            model = self.__build_model(i_fold)\n",
    "            model.load_model()\n",
    "            pred = model.predict(self.X_test[self.feature_names])\n",
    "            preds.append(pred)\n",
    "\n",
    "        # mean of the prediction values\n",
    "        pred_mean = np.mean(preds, axis=0)\n",
    "        df_pred = self.X_test[self.X_test.columns[:2]]\n",
    "        df_pred.loc[:, 'target'] = pred_mean\n",
    "        return df_pred\n",
    "\n",
    "    def run_train_all(self) -> None:\n",
    "        ''' learns with all the training data and save the model '''\n",
    "        # learning\n",
    "        i_fold = 'all'\n",
    "        model, _, _, _ = self.__train_fold(i_fold)\n",
    "        model.save_model()\n",
    "\n",
    "    def run_predict_all(self) -> pd.DataFrame:\n",
    "        ''' predicts for test data with the model learned with all the training data\n",
    "\n",
    "        :return: predicted target\n",
    "        '''\n",
    "        \n",
    "        # predict with the mdoel learned with all the learning data\n",
    "        i_fold = 'all'\n",
    "        model = self.__build_model(i_fold)\n",
    "        model.load_model()\n",
    "        pred = model.predict(self.X_test[self.feature_names])\n",
    "        df_pred = self.X_test[self.X_test.columns[:2]]\n",
    "        df_pred['target'] = pred\n",
    "        return df_pred\n",
    "\n",
    "    def __build_model(self, i_fold: Union[int, str]) -> Model:\n",
    "        ''' builds a model with a specified fold for cv\n",
    "\n",
    "        :param i_fold: number of fold\n",
    "        :return: instance of model\n",
    "        '''\n",
    "        # build a model with run name, fold, and class of model\n",
    "        run_fold_name = f'{self.run_name}-{i_fold}'\n",
    "        return self.model_cls(run_fold_name, self.feature_names, self.params)\n",
    "\n",
    "    def __load_y_train(self) -> pd.DataFrame:\n",
    "        ''' loads target of train data; ['stock_id', 'time_id', 'target']\n",
    "\n",
    "        :return: target dataframe of train data\n",
    "        '''\n",
    "        return pd.read_csv(DATA_DIR + 'train.csv')\n",
    "    \"\"\"\n",
    "    def __load_index_fold(self, i_fold: int) -> np.array:\n",
    "        ''' returns the record index in response to the fold specified for cv\n",
    "\n",
    "        :param i_fold: number of the fold\n",
    "        :return: record index for the fold\n",
    "        '''\n",
    "        # return index to split data for learning and validation\n",
    "        y_train = self.__load_y_train()\n",
    "        x_dummy = np.zeros(len(y_train))\n",
    "        skf = KFold(n_splits=self.n_fold, shuffle=True, random_state=31)\n",
    "        return list(skf.split(x_dummy, y_train))[i_fold]\n",
    "    \"\"\"\n",
    "    def __load_index_fold(self, i_fold: int) -> np.array:\n",
    "        ''' returns the record index in response to the fold specified for cv\n",
    "\n",
    "        :param i_fold: number of the fold\n",
    "        :return: record index for the fold\n",
    "        '''\n",
    "        # return index to split data for learning and validation\n",
    "        y_train = self.__load_y_train()\n",
    "        kf = KFold(n_splits=4, shuffle=True, random_state=31)\n",
    "        idx_timeid = list(kf.split(y_train.time_id.unique()))[i_fold]\n",
    "        idx_train = y_train.loc[y_train.time_id.isin(idx_timeid[0])].index\n",
    "        idx_test = y_train.loc[y_train.time_id.isin(idx_timeid[1])].index\n",
    "        return idx_train, idx_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_lgb = {\n",
    "            'boosting_type': 'gbdt',\n",
    "            'metric': 'rmse',\n",
    "            'num_boost_round': 100\n",
    "            }\n",
    "\n",
    "df_features_train = create_df_features(cf, \"train\")\n",
    "df_features_test = create_df_features(cf, \"test\")\n",
    "feature_names = cf.feature_names\n",
    "'''\n",
    "df_features_train.to_csv('df_features_train.csv', index=False, encoding='utf-8')\n",
    "df_features_test.to_csv('df_features_test.csv', index=False, encoding='utf-8')\n",
    "'''\n",
    "'''\n",
    "df_features_train = pd.read_csv('df_features_train.csv')\n",
    "df_features_test = pd.read_csv('df_features_test.csv')\n",
    "feature_names = df_features_train.columns\n",
    "'''\n",
    "run_name = 'lgb'\n",
    "runner = Runner(run_name=run_name,\n",
    "                model_cls=ModelLGB,\n",
    "                feature_names=feature_names,\n",
    "                df_features_train=df_features_train,\n",
    "                df_features_test=df_features_test,\n",
    "                params=params_lgb)\n",
    "runner.run_train_cv()\n",
    "pred = runner.run_predict_cv()\n",
    "Util.submission(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5873a2e4ae71a6ad4e701fe25eee82d2fb1d0c5d039043e545c04b75e9a3a94f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('.venv': poetry)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
