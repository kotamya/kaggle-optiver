{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\r\n",
    "import joblib\r\n",
    "import lightgbm\r\n",
    "import optuna.integration.lightgbm as lgb\r\n",
    "import numpy as np\r\n",
    "import os\r\n",
    "import pandas as pd\r\n",
    "from abc import ABCMeta, abstractmethod\r\n",
    "from scipy.stats import median_absolute_deviation\r\n",
    "from sklearn.model_selection import KFold\r\n",
    "from tqdm import tqdm\r\n",
    "from typing import Callable, List, Tuple, Union, Optional, Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../input/optiver-realized-volatility-prediction/'\r\n",
    "\r\n",
    "def read_book(train_test: str, stock_id: int):\r\n",
    "    if stock_id is None:\r\n",
    "        return pd.concat(read_book(train_test, i) for i in range(127))\r\n",
    "\r\n",
    "    book = pd.read_parquet(DATA_DIR + f\"book_{train_test}.parquet/stock_id={stock_id}\")\r\n",
    "    book[\"stock_id\"] = stock_id\r\n",
    "    return book\r\n",
    "\r\n",
    "\r\n",
    "def read_trade(train_test: str, stock_id: int):\r\n",
    "    if stock_id is None:\r\n",
    "        return pd.concat(read_trade(train_test, i) for i in range(127))\r\n",
    "\r\n",
    "    trade = pd.read_parquet(DATA_DIR + f\"trade_{train_test}.parquet/stock_id={stock_id}\")\r\n",
    "    trade[\"stock_id\"] = stock_id\r\n",
    "    return trade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to compute features from book\r\n",
    "\r\n",
    "\r\n",
    "def wap(book: pd.DataFrame) -> pd.Series:\r\n",
    "    return (\r\n",
    "        book[\"bid_price1\"] * book[\"ask_size1\"] + book[\"ask_price1\"] * book[\"bid_size1\"]\r\n",
    "    ) / (book[\"bid_size1\"] + book[\"ask_size1\"])\r\n",
    "\r\n",
    "\r\n",
    "def wap2(book: pd.DataFrame) -> pd.Series:\r\n",
    "    return (\r\n",
    "        book[\"bid_price2\"] * book[\"ask_size2\"] + book[\"ask_price2\"] * book[\"bid_size2\"]\r\n",
    "    ) / (book[\"bid_size2\"] + book[\"ask_size2\"])\r\n",
    "\r\n",
    "\r\n",
    "def price_spread1(book: pd.DataFrame) -> pd.Series:\r\n",
    "    return book[\"ask_price1\"] - book[\"bid_price1\"]\r\n",
    "\r\n",
    "\r\n",
    "def price_spread2(book: pd.DataFrame) -> pd.Series:\r\n",
    "    return book[\"ask_price2\"] - book[\"bid_price2\"]\r\n",
    "\r\n",
    "\r\n",
    "def price_spread_bid(book: pd.DataFrame) -> pd.Series:\r\n",
    "    return book[\"bid_price1\"] - book[\"bid_price2\"]\r\n",
    "\r\n",
    "\r\n",
    "def price_spread_ask(book: pd.DataFrame) -> pd.Series:\r\n",
    "    return book[\"ask_price1\"] - book[\"ask_price2\"]\r\n",
    "\r\n",
    "\r\n",
    "def size_total_bid(book: pd.DataFrame) -> pd.Series:\r\n",
    "    return book['bid_size1'] + book['bid_size2']\r\n",
    "\r\n",
    "\r\n",
    "def size_total_ask(book: pd.DataFrame) -> pd.Series:\r\n",
    "    return book['ask_size1'] + book['ask_size2']\r\n",
    "\r\n",
    "\r\n",
    "def size_total1(book: pd.DataFrame) -> pd.Series:\r\n",
    "    return book['bid_size1'] + book['ask_size1']\r\n",
    "\r\n",
    "\r\n",
    "def size_total2(book: pd.DataFrame) -> pd.Series:\r\n",
    "    return book['bid_size2'] + book['ask_size2']\r\n",
    "\r\n",
    "\r\n",
    "def size_total3(book: pd.DataFrame) -> pd.Series:\r\n",
    "    return book['bid_size1'] + book['bid_size2'] + book['ask_size1'] + book['ask_size2']\r\n",
    "\r\n",
    "\r\n",
    "def size_spread1(book: pd.DataFrame) -> pd.Series:\r\n",
    "    return book['bid_size1'] - book['ask_size1']\r\n",
    "\r\n",
    "\r\n",
    "def size_spread2(book: pd.DataFrame) -> pd.Series:\r\n",
    "    return book['bid_size2'] - book['ask_size2']\r\n",
    "\r\n",
    "\r\n",
    "def size_spread3(book: pd.DataFrame) -> pd.Series:\r\n",
    "    return book['bid_size1'] + book['bid_size2'] - book['ask_size1'] - book['ask_size2']\r\n",
    "\r\n",
    "\r\n",
    "def log_return(book: pd.DataFrame) -> pd.Series:\r\n",
    "    return wap(book).groupby(book.time_id).apply(np.log).diff()\r\n",
    "\r\n",
    "\r\n",
    "def log_return2(book: pd.DataFrame) -> pd.Series:\r\n",
    "    return wap2(book).groupby(book.time_id).apply(np.log).diff()\r\n",
    "\r\n",
    "\r\n",
    "def instvar(book: pd.DataFrame):\r\n",
    "    \"\"\"Compute instantaneous variance.\"\"\"\r\n",
    "    return log_return(book) ** 2\r\n",
    "\r\n",
    "\r\n",
    "def instvar2(book: pd.DataFrame):\r\n",
    "    \"\"\"Compute instantaneous variance.\"\"\"\r\n",
    "    return log_return2(book) ** 2\r\n",
    "\r\n",
    "\r\n",
    "def updown(book: pd.DataFrame) -> pd.Series:\r\n",
    "    n_samples = 10\r\n",
    "    wap_groupby = wap(book).groupby(book.time_id)\r\n",
    "    head = wap_groupby.head(n_samples).groupby(book.time_id).mean()\r\n",
    "    tail = wap_groupby.tail(n_samples).groupby(book.time_id).mean()\r\n",
    "    return (tail - head).apply(np.sign)\r\n",
    "\r\n",
    "\r\n",
    "def stock_id(book: pd.DataFrame) -> pd.Series:\r\n",
    "    return book.stock_id.groupby(book.time_id).first()\r\n",
    "\r\n",
    "\r\n",
    "def time_id(book: pd.DataFrame) -> pd.Series:\r\n",
    "    return book.time_id.groupby(book.time_id).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to compute features from trade\r\n",
    "\r\n",
    "def trade__size(trade: pd.DataFrame) -> pd.Series:\r\n",
    "    return trade['size']\r\n",
    "\r\n",
    "def trade__price(trade: pd.DataFrame) -> pd.Series:\r\n",
    "    return trade['price']\r\n",
    "\r\n",
    "def trade__order_count(trade: pd.DataFrame) -> pd.Series:\r\n",
    "    return trade['order_count']\r\n",
    "\r\n",
    "def trade__true_range(trade: pd.DataFrame) -> pd.Series:\r\n",
    "    return trade['price'].max() - trade['price'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\r\n",
    "\r\n",
    "\r\n",
    "def derive(fn: Callable, name=None, **kwargs) -> Callable:\r\n",
    "    \"\"\"Derive a function,named name,which when called will behave like\r\n",
    "    fn called with the keyword arguments kwargs.\r\n",
    "    \"\"\"\r\n",
    "    function = partial(fn, **kwargs)\r\n",
    "    if name is not None:\r\n",
    "        function.__name__ = name\r\n",
    "    return function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregation Functions\r\n",
    "\r\n",
    "\r\n",
    "def ewm(series: pd.Series, halflife: float = 10.0) -> pd.Series:\r\n",
    "    return series.ewm(halflife=halflife).mean().iat[-1]\r\n",
    "\r\n",
    "\r\n",
    "ewm10 = derive(ewm, \"ewm10\", halflife=10.0)\r\n",
    "ewm20 = derive(ewm, \"ewm20\", halflife=20.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\r\n",
    "\r\n",
    "\r\n",
    "class CreateFeatures:\r\n",
    "    \"\"\"Class to compute features.\r\n",
    "\r\n",
    "    Args:\r\n",
    "        features: list[dict[str, (Callable, Callable)]]\r\n",
    "            Each key is the name of a feature.\r\n",
    "            Each value is a tuple: ``(fn, agg)`` where fn is a function applied to the book \r\n",
    "            to make series and agg is an aggregation function\r\n",
    "\r\n",
    "            If agg is not None:\r\n",
    "                feature (pd.Series) will be computed by 1) applying fn to a book,\r\n",
    "                2) aggregating the output by `time_id`, and then \r\n",
    "                3) aggregate the groupby object with agg.\r\n",
    "                fn receives pd.DataFrame of book and returns pd.Series of feature time-series.\r\n",
    "                agg is any aggregation function that can be passed to pd.SeriesGroupby.agg.\r\n",
    "\r\n",
    "            If agg is None:\r\n",
    "                feature will be computed by fn(book).\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    def __init__(self, features: List[Tuple[Callable, Callable]]) -> None:\r\n",
    "        # attribute _features is:\r\n",
    "        # each key: name of feature \"{fn name}__{aggregation name}\"\r\n",
    "        # each value: (fn, agg) \r\n",
    "        self.__features = OrderedDict()\r\n",
    "        for fn, agg in features:\r\n",
    "            name = self.__feature_name(fn, agg)\r\n",
    "            self.register_feature(name, fn=fn, agg=agg)\r\n",
    "\r\n",
    "    def compute_df_features(self, book, trade) -> pd.DataFrame:\r\n",
    "        return pd.merge(\r\n",
    "                        pd.DataFrame(\r\n",
    "                        {\r\n",
    "                            name: self.__compute_feature(book, fn, agg)\r\n",
    "                            for name, fn, agg in self.features()\r\n",
    "                            if not 'trade__' in name\r\n",
    "                        }\r\n",
    "                        ).reset_index(drop=True),\r\n",
    "                        pd.DataFrame(\r\n",
    "                        {\r\n",
    "                            name: self.__compute_feature(trade, fn, agg)\r\n",
    "                            for name, fn, agg in self.features()\r\n",
    "                            if \"trade__\" in name or \"stock_id\" in name or \"time_id\" in name\r\n",
    "                        }\r\n",
    "                        ).reset_index(drop=True),\r\n",
    "                        on=[\"stock_id\", \"time_id\"],\r\n",
    "                        how=\"outer\"\r\n",
    "        )\r\n",
    "\r\n",
    "    def register_feature(self, name, fn, agg) -> None:\r\n",
    "        \"\"\"Adds a feature to the class.\"\"\"\r\n",
    "        self.__features[name] = (fn, agg)\r\n",
    "        \r\n",
    "    def features(self) -> Iterable:\r\n",
    "        \"\"\"Returns an iterator over (name, fn, agg) of features.\"\"\"\r\n",
    "        for name, (fn, agg) in self.__features.items():\r\n",
    "            yield (name, fn, agg)\r\n",
    "\r\n",
    "    @property\r\n",
    "    def feature_names(self) -> List[str]:\r\n",
    "        return list(self.__features.keys())\r\n",
    "\r\n",
    "    def __feature_name(self, fn, agg) -> str:\r\n",
    "        name = fn.__name__\r\n",
    "        if agg is not None:\r\n",
    "            name += \"__\" + (agg if isinstance(agg, str) else agg.__name__)\r\n",
    "        return name\r\n",
    "\r\n",
    "    def __compute_feature(self, book_trade, fn, agg) -> pd.Series:\r\n",
    "        output = fn(book_trade)\r\n",
    "        if agg is not None:\r\n",
    "            output = output.groupby(book_trade.time_id).agg(agg)\r\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\r\n",
    "\r\n",
    "features = [\r\n",
    "    # book\r\n",
    "    (stock_id, None),\r\n",
    "    (time_id, None),\r\n",
    "    (instvar, np.mean),  # volatility\r\n",
    "    (instvar2, np.mean),  # volatility\r\n",
    "    (updown, None),\r\n",
    "    # trade\r\n",
    "    (trade__true_range, None),\r\n",
    "]\r\n",
    "\r\n",
    "fns = [\r\n",
    "    # book\r\n",
    "    price_spread1, price_spread2, price_spread_bid, price_spread_ask, size_total_bid, size_total_ask,\r\n",
    "    size_total1, size_total2, size_total3, size_spread1, size_spread2, size_spread3,\r\n",
    "    # trade\r\n",
    "    trade__size, trade__price, trade__order_count,\r\n",
    "    ]\r\n",
    "aggs = [np.mean, np.max, np.min, median_absolute_deviation, np.std, ewm10, ewm20]\r\n",
    "\r\n",
    "\r\n",
    "for fn, agg in product(fns, aggs):\r\n",
    "    features.append((fn, agg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = CreateFeatures(features)\r\n",
    "\r\n",
    "cf.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_features(cf: CreateFeatures, train_test: str = None) -> pd.DataFrame:\r\n",
    "    paths = glob.glob(DATA_DIR + f\"book_{train_test}.parquet/*\")\r\n",
    "    dfs = []\r\n",
    "    for path in tqdm(paths):\r\n",
    "        book = pd.read_parquet(path)\r\n",
    "        trade = pd.read_parquet(path.replace('book', 'trade'))\r\n",
    "        book[\"stock_id\"] = trade[\"stock_id\"] = int(path.split(\"=\")[-1])\r\n",
    "        dfs.append(cf.compute_df_features(book, trade))\r\n",
    "    df_features = pd.concat(dfs).reset_index(drop=True)\r\n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(metaclass=ABCMeta):\r\n",
    "\r\n",
    "    def __init__(self, run_fold_name: str, feature_names: List[str],\r\n",
    "                 params: dict) -> None:\r\n",
    "        ''' Constructor\r\n",
    "\r\n",
    "        :param feature_names: list of feature names to specify columns of feature dataframe\r\n",
    "        :param params: hyper parameters\r\n",
    "        '''\r\n",
    "        self.run_fold_name = run_fold_name\r\n",
    "        self.feature_names = feature_names\r\n",
    "        self.params = params\r\n",
    "        self.model = None\r\n",
    "\r\n",
    "    @abstractmethod\r\n",
    "    def train(self, X_train: pd.DataFrame, y_train: pd.Series,\r\n",
    "              X_valid: Optional[pd.DataFrame] = None,\r\n",
    "              y_valid: Optional[pd.Series] = None\r\n",
    "              ) -> None:\r\n",
    "        ''' trains a model\r\n",
    "\r\n",
    "        :param X_train: features of training data\r\n",
    "        :param y_train: targets of training data\r\n",
    "        :param X_valid: features of validation data\r\n",
    "        :param y_valid: targets of validation data\r\n",
    "        '''\r\n",
    "        pass\r\n",
    "\r\n",
    "    @abstractmethod\r\n",
    "    def predict(self, X: pd.DataFrame) -> np.array:\r\n",
    "        ''' returns prediction output from a learned model\r\n",
    "\r\n",
    "        :param X: features of test data or validation data\r\n",
    "        :return: predicted value\r\n",
    "        '''\r\n",
    "        pass\r\n",
    "\r\n",
    "    @abstractmethod\r\n",
    "    def save_model(self) -> None:\r\n",
    "        ''' saves a model '''\r\n",
    "        pass\r\n",
    "\r\n",
    "    @abstractmethod\r\n",
    "    def load_model(self) -> None:\r\n",
    "        ''' loads a model '''\r\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelLGB(Model):\r\n",
    "\r\n",
    "\r\n",
    "    def train(self, X_train, y_train, X_valid=None, y_valid=None):\r\n",
    "\r\n",
    "        params = self.params\r\n",
    "        if X_valid is not None:\r\n",
    "            # weights to change feval from RMSE to RMSPE\r\n",
    "            # idea from: https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/250324\r\n",
    "            w_train = 1/np.square(y_train)\r\n",
    "            w_valid = 1/np.square(y_valid)\r\n",
    "            lgb_train = lgb.Dataset(X_train, y_train, weight=w_train)\r\n",
    "            lgb_eval = lgb.Dataset(X_valid, y_valid, weight=w_valid)\r\n",
    "            self.model = lgb.train(params,\r\n",
    "                                   lgb_train,\r\n",
    "                                   valid_sets=lgb_eval,\r\n",
    "                                   feval=rmspe,\r\n",
    "                                   verbose_eval=100,\r\n",
    "                                   early_stopping_rounds=100,\r\n",
    "                                   categorical_feature=['stock_id'],\r\n",
    "                                  )\r\n",
    "        else:\r\n",
    "            w_train = 1/np.square(y_train)\r\n",
    "            lgb_train = lgb.Dataset(X_train, y_train, weight=w_train)\r\n",
    "            self.model = lgb.train(params,\r\n",
    "                                   lgb_train,\r\n",
    "                                   num_boost_round=100,\r\n",
    "                                   feval=rmspe,\r\n",
    "                                   categorical_feature=['stock_id'],\r\n",
    "                           )\r\n",
    "\r\n",
    "    def predict(self, X_test):\r\n",
    "        return self.model.predict(X_test)\r\n",
    "\r\n",
    "    def save_model(self):\r\n",
    "        self.model.save_model('model.txt')\r\n",
    "\r\n",
    "    def load_model(self):\r\n",
    "        self.model = lgb.Booster(model_file='model.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delf-defiend evaluation metric function\r\n",
    "def rmspe(y_true: np.array, y_pred: np.array):\r\n",
    "    ''' self-defined eval metric\r\n",
    "        Root Mean Squared Percentage Error\r\n",
    "\r\n",
    "    :return: name: str, eval_result: float, is_higher_better: bool\r\n",
    "    '''\r\n",
    "    if type(y_pred) == lightgbm.basic.Dataset:\r\n",
    "        y_pred = y_pred.get_label()\r\n",
    "    rmspe = (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true))))\r\n",
    "    return 'RMSPE', rmspe, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Util:\r\n",
    "    @classmethod\r\n",
    "    def dump(cls, value, path):\r\n",
    "        os.makedirs(os.path.dirname(path), exist_ok=True)\r\n",
    "        joblib.dump(value, path, compress=True)\r\n",
    "\r\n",
    "    @classmethod\r\n",
    "    def load(cls, path):\r\n",
    "        return joblib.load(path)\r\n",
    "\r\n",
    "    @classmethod\r\n",
    "    def submission(cls, df_pred: pd.DataFrame) -> None:\r\n",
    "        row_id = df_pred['stock_id'].apply(str) + '-' + df_pred['time_id'].apply(str)\r\n",
    "        df_submission = pd.DataFrame({'row_id': row_id, 'target':df_pred['target']})\r\n",
    "        df_submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Runner:\r\n",
    "\r\n",
    "    def __init__(self, run_name: str, model_cls: Callable[[str, dict], Model],\r\n",
    "                 feature_names: List[str], df_features_train: pd.DataFrame,\r\n",
    "                 df_features_test: pd.DataFrame, params: dict):\r\n",
    "        ''' Constructor\r\n",
    "\r\n",
    "        :param run_name: name of run\r\n",
    "        :param model_cls: class of model\r\n",
    "        :param feature_names: list of feature names\r\n",
    "        :param params: hyper parameters\r\n",
    "        '''\r\n",
    "        self.run_name = run_name\r\n",
    "        self.model_cls = model_cls\r\n",
    "        self.feature_names = feature_names\r\n",
    "        self.X_train_all = df_features_train\r\n",
    "        self.X_test = df_features_test\r\n",
    "        self.params = params\r\n",
    "        self.n_fold = 4\r\n",
    "\r\n",
    "    def __train_fold(self, i_fold: Union[int, str]) -> Tuple[\r\n",
    "                    Model, Optional[np.array],\r\n",
    "                    Optional[np.array], Optional[float]]:\r\n",
    "        ''' specifies number of fold for cv then learns & evaluates\r\n",
    "\r\n",
    "        :param i_fold: number of fold ('all' for all)\r\n",
    "        :return: a tuple of instance of model, index of record,\r\n",
    "                 predicted value, and evaluation score\r\n",
    "                 (returns only model if i_fold=='all')\r\n",
    "        '''\r\n",
    "        # load train data\r\n",
    "        y_train_all = self.__load_y_train()\r\n",
    "        self.X_train_all['stock_id'] = self.X_train_all['stock_id'].astype('int64')\r\n",
    "        self.X_train_all['time_id'] = self.X_train_all['time_id'].astype('int64')\r\n",
    "        Xy_train_all = pd.merge(self.X_train_all, y_train_all,\r\n",
    "                                left_on=['stock_id','time_id'], right_on=['stock_id','time_id'],\r\n",
    "                                how='inner')\r\n",
    "        X_train_all = Xy_train_all[self.feature_names]\r\n",
    "        y_train_all = Xy_train_all['target']\r\n",
    "\r\n",
    "        validation = i_fold != 'all'\r\n",
    "        if validation:\r\n",
    "            # split data into training and validation\r\n",
    "            idx_train, idx_valid = self.__load_index_fold(i_fold)\r\n",
    "            X_train = X_train_all.iloc[idx_train]\r\n",
    "            y_train = y_train_all.iloc[idx_train]\r\n",
    "            X_valid = X_train_all.iloc[idx_valid]\r\n",
    "            y_valid = y_train_all.iloc[idx_valid]\r\n",
    "\r\n",
    "            # execute learning\r\n",
    "            model = self.__build_model(i_fold)\r\n",
    "            model.train(X_train, y_train, X_valid, y_valid)\r\n",
    "\r\n",
    "            # prediction and evaluation with validation data\r\n",
    "            pred_valid = model.predict(X_valid)\r\n",
    "            _, score, _ = rmspe(y_true=y_valid, y_pred=pred_valid)\r\n",
    "\r\n",
    "            # return model, index, prediction, and score\r\n",
    "            return model, idx_valid, pred_valid, score\r\n",
    "        else:\r\n",
    "            # learining with all data\r\n",
    "            model = self.__build_model(i_fold)\r\n",
    "            model.train(X_train_all, y_train_all)\r\n",
    "\r\n",
    "            # return model\r\n",
    "            return model, None, None, None\r\n",
    "\r\n",
    "    def run_train_cv(self) -> None:\r\n",
    "        ''' learns and evaluates by CV\r\n",
    "\r\n",
    "        learns, evaluates, and saves models and scores of each fold\r\n",
    "        '''\r\n",
    "        scores = []\r\n",
    "        idxes_valid = []\r\n",
    "        preds = []\r\n",
    "\r\n",
    "        # learning for each fold\r\n",
    "        for i_fold in range(self.n_fold):\r\n",
    "            model, idx_valid, pred_valid, score = self.__train_fold(i_fold)\r\n",
    "\r\n",
    "            # hold result\r\n",
    "            idxes_valid.append(idx_valid)\r\n",
    "            scores.append(score)\r\n",
    "            preds.append(pred_valid)\r\n",
    "\r\n",
    "            # save model\r\n",
    "            model.save_model()\r\n",
    "        print(f'Mean score of the folds: {np.mean(scores)}')\r\n",
    "\r\n",
    "    def run_predict_cv(self) -> pd.DataFrame:\r\n",
    "        ''' predicts for test data with the mean of\r\n",
    "            each fold's model learned through CV\r\n",
    "            \r\n",
    "            :return: predicted target as the mean of folds\r\n",
    "        '''\r\n",
    "        preds = []\r\n",
    "        # prediction for each fold's model\r\n",
    "        for i_fold in range(self.n_fold):\r\n",
    "            model = self.__build_model(i_fold)\r\n",
    "            model.load_model()\r\n",
    "            pred = model.predict(self.X_test[self.feature_names])\r\n",
    "            preds.append(pred)\r\n",
    "\r\n",
    "        # mean of the prediction values\r\n",
    "        pred_mean = np.mean(preds, axis=0)\r\n",
    "        df_pred = self.X_test[self.X_test.columns[:2]]\r\n",
    "        df_pred.loc[:, 'target'] = pred_mean\r\n",
    "        return df_pred\r\n",
    "\r\n",
    "    def run_train_all(self) -> None:\r\n",
    "        ''' learns with all the training data and save the model '''\r\n",
    "        # learning\r\n",
    "        i_fold = 'all'\r\n",
    "        model, _, _, _ = self.__train_fold(i_fold)\r\n",
    "        model.save_model()\r\n",
    "\r\n",
    "    def run_predict_all(self) -> pd.DataFrame:\r\n",
    "        ''' predicts for test data with the model learned with all the training data\r\n",
    "\r\n",
    "        :return: predicted target\r\n",
    "        '''\r\n",
    "        \r\n",
    "        # predict with the mdoel learned with all the learning data\r\n",
    "        i_fold = 'all'\r\n",
    "        model = self.__build_model(i_fold)\r\n",
    "        model.load_model()\r\n",
    "        pred = model.predict(self.X_test[self.feature_names])\r\n",
    "        df_pred = self.X_test[self.X_test.columns[:2]]\r\n",
    "        df_pred['target'] = pred\r\n",
    "        return df_pred\r\n",
    "\r\n",
    "    def __build_model(self, i_fold: Union[int, str]) -> Model:\r\n",
    "        ''' builds a model with a specified fold for cv\r\n",
    "\r\n",
    "        :param i_fold: number of fold\r\n",
    "        :return: instance of model\r\n",
    "        '''\r\n",
    "        # build a model with run name, fold, and class of model\r\n",
    "        run_fold_name = f'{self.run_name}-{i_fold}'\r\n",
    "        return self.model_cls(run_fold_name, self.feature_names, self.params)\r\n",
    "\r\n",
    "    def __load_y_train(self) -> pd.DataFrame:\r\n",
    "        ''' loads target of train data; ['stock_id', 'time_id', 'target']\r\n",
    "\r\n",
    "        :return: target dataframe of train data\r\n",
    "        '''\r\n",
    "        return pd.read_csv(DATA_DIR + 'train.csv')\r\n",
    "\r\n",
    "    def __load_index_fold(self, i_fold: int) -> np.array:\r\n",
    "        ''' returns the record index in response to the fold specified for cv\r\n",
    "\r\n",
    "        :param i_fold: number of the fold\r\n",
    "        :return: record index for the fold\r\n",
    "        '''\r\n",
    "        # return index to split data for learning and validation\r\n",
    "        y_train = self.__load_y_train()\r\n",
    "        x_dummy = np.zeros(len(y_train))\r\n",
    "        skf = KFold(n_splits=self.n_fold, shuffle=True, random_state=31)\r\n",
    "        return list(skf.split(x_dummy, y_train))[i_fold]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_lgb = {\r\n",
    "            'boosting_type': 'gbdt',\r\n",
    "            'metric': 'rmse',\r\n",
    "            }\r\n",
    "\r\n",
    "df_features_train = create_df_features(cf, \"train\")\r\n",
    "df_features_test = create_df_features(cf, \"test\")\r\n",
    "feature_names = cf.feature_names\r\n",
    "\r\n",
    "run_name = 'lgb'\r\n",
    "runner = Runner(run_name=run_name,\r\n",
    "                model_cls=ModelLGB,\r\n",
    "                feature_names=feature_names,\r\n",
    "                df_features_train=df_features_train,\r\n",
    "                df_features_test=df_features_test,\r\n",
    "                params=params_lgb)\r\n",
    "runner.run_train_cv()\r\n",
    "pred = runner.run_predict_cv()\r\n",
    "Util.submission(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "123ef78029e45cba9d6951e4ccbdaba0b0d99d8cf41cf61f7566ca31b4f1d296"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('optiver-env': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
