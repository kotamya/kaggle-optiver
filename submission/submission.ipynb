{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "import glob\r\n",
                "import joblib\r\n",
                "import lightgbm as lgb\r\n",
                "import numpy as np\r\n",
                "import os\r\n",
                "import pandas as pd\r\n",
                "from abc import ABCMeta, abstractmethod\r\n",
                "from scipy.stats import median_absolute_deviation\r\n",
                "from sklearn.model_selection import KFold\r\n",
                "from tqdm import tqdm\r\n",
                "from typing import Callable, List, Tuple, Union, Optional, Iterable"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "source": [
                "DATA_DIR = '../input/optiver-realized-volatility-prediction/'\r\n",
                "\r\n",
                "def read_book(train_test: str, stock_id: int):\r\n",
                "    if stock_id is None:\r\n",
                "        return pd.concat(read_book(train_test, i) for i in range(127))\r\n",
                "\r\n",
                "    book = pd.read_parquet(DATA_DIR + f\"book_{train_test}.parquet/stock_id={stock_id}\")\r\n",
                "    book[\"stock_id\"] = stock_id\r\n",
                "    return book\r\n",
                "\r\n",
                "\r\n",
                "def read_trade(train_test: str, stock_id: int):\r\n",
                "    if stock_id is None:\r\n",
                "        return pd.concat(read_trade(train_test, i) for i in range(127))\r\n",
                "\r\n",
                "    trade = pd.read_parquet(DATA_DIR + f\"trade_{train_test}.parquet/stock_id={stock_id}\")\r\n",
                "    trade[\"stock_id\"] = stock_id\r\n",
                "    return trade"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "# Functions to compute features from book\r\n",
                "\r\n",
                "\r\n",
                "def wap(book: pd.DataFrame) -> pd.Series:\r\n",
                "    return (\r\n",
                "        book[\"bid_price1\"] * book[\"ask_size1\"] + book[\"ask_price1\"] * book[\"bid_size1\"]\r\n",
                "    ) / (book[\"bid_size1\"] + book[\"ask_size1\"])\r\n",
                "\r\n",
                "\r\n",
                "def wap2(book: pd.DataFrame) -> pd.Series:\r\n",
                "    return (\r\n",
                "        book[\"bid_price2\"] * book[\"ask_size2\"] + book[\"ask_price2\"] * book[\"bid_size2\"]\r\n",
                "    ) / (book[\"bid_size2\"] + book[\"ask_size2\"])\r\n",
                "\r\n",
                "\r\n",
                "def price_spread1(book: pd.DataFrame) -> pd.Series:\r\n",
                "    return book[\"ask_price1\"] - book[\"bid_price1\"]\r\n",
                "\r\n",
                "\r\n",
                "def price_spread2(book: pd.DataFrame) -> pd.Series:\r\n",
                "    return book[\"ask_price2\"] - book[\"bid_price2\"]\r\n",
                "\r\n",
                "\r\n",
                "def price_spread_bid(book: pd.DataFrame) -> pd.Series:\r\n",
                "    return book[\"bid_price1\"] - book[\"bid_price2\"]\r\n",
                "\r\n",
                "\r\n",
                "def price_spread_ask(book: pd.DataFrame) -> pd.Series:\r\n",
                "    return book[\"ask_price1\"] - book[\"ask_price2\"]\r\n",
                "\r\n",
                "\r\n",
                "def size_total_bid(book: pd.DataFrame) -> pd.Series:\r\n",
                "    return book['bid_size1'] + book['bid_size2']\r\n",
                "\r\n",
                "\r\n",
                "def size_total_ask(book: pd.DataFrame) -> pd.Series:\r\n",
                "    return book['ask_size1'] + book['ask_size2']\r\n",
                "\r\n",
                "\r\n",
                "def size_total1(book: pd.DataFrame) -> pd.Series:\r\n",
                "    return book['bid_size1'] + book['ask_size1']\r\n",
                "\r\n",
                "\r\n",
                "def size_total2(book: pd.DataFrame) -> pd.Series:\r\n",
                "    return book['bid_size2'] + book['ask_size2']\r\n",
                "\r\n",
                "\r\n",
                "def size_total3(book: pd.DataFrame) -> pd.Series:\r\n",
                "    return book['bid_size1'] + book['bid_size2'] + book['ask_size1'] + book['ask_size2']\r\n",
                "\r\n",
                "\r\n",
                "def size_spread1(book: pd.DataFrame) -> pd.Series:\r\n",
                "    return book['bid_size1'] - book['ask_size1']\r\n",
                "\r\n",
                "\r\n",
                "def size_spread2(book: pd.DataFrame) -> pd.Series:\r\n",
                "    return book['bid_size2'] - book['ask_size2']\r\n",
                "\r\n",
                "\r\n",
                "def size_spread3(book: pd.DataFrame) -> pd.Series:\r\n",
                "    return book['bid_size1'] + book['bid_size2'] - book['ask_size1'] - book['ask_size2']\r\n",
                "\r\n",
                "\r\n",
                "def log_return(book: pd.DataFrame) -> pd.Series:\r\n",
                "    return wap(book).groupby(book.time_id).apply(np.log).diff()\r\n",
                "\r\n",
                "\r\n",
                "def log_return2(book: pd.DataFrame) -> pd.Series:\r\n",
                "    return wap2(book).groupby(book.time_id).apply(np.log).diff()\r\n",
                "\r\n",
                "\r\n",
                "def instvar(book: pd.DataFrame):\r\n",
                "    \"\"\"Compute instantaneous variance.\"\"\"\r\n",
                "    return log_return(book) ** 2\r\n",
                "\r\n",
                "\r\n",
                "def instvar2(book: pd.DataFrame):\r\n",
                "    \"\"\"Compute instantaneous variance.\"\"\"\r\n",
                "    return log_return2(book) ** 2\r\n",
                "\r\n",
                "\r\n",
                "def updown(book: pd.DataFrame) -> pd.Series:\r\n",
                "    n_samples = 10\r\n",
                "    wap_groupby = wap(book).groupby(book.time_id)\r\n",
                "    head = wap_groupby.head(n_samples).groupby(book.time_id).mean()\r\n",
                "    tail = wap_groupby.tail(n_samples).groupby(book.time_id).mean()\r\n",
                "    return (tail - head).apply(np.sign)\r\n",
                "\r\n",
                "\r\n",
                "def stock_id(book: pd.DataFrame) -> pd.Series:\r\n",
                "    return book.stock_id.groupby(book.time_id).first()\r\n",
                "\r\n",
                "\r\n",
                "def time_id(book: pd.DataFrame) -> pd.Series:\r\n",
                "    return book.time_id.groupby(book.time_id).first()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "# Functions to compute features from trade\r\n",
                "\r\n",
                "def trade__size(trade: pd.DataFrame) -> pd.Series:\r\n",
                "    return trade['size']\r\n",
                "\r\n",
                "def trade__price(trade: pd.DataFrame) -> pd.Series:\r\n",
                "    return trade['price']\r\n",
                "\r\n",
                "def trade__order_count(trade: pd.DataFrame) -> pd.Series:\r\n",
                "    return trade['order_count']\r\n",
                "\r\n",
                "def trade__true_range(trade: pd.DataFrame) -> pd.Series:\r\n",
                "    return trade['price'].max() - trade['price'].min()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "from functools import partial\r\n",
                "\r\n",
                "\r\n",
                "def derive(fn: Callable, name=None, **kwargs) -> Callable:\r\n",
                "    \"\"\"Derive a function,named name,which when called will behave like\r\n",
                "    fn called with the keyword arguments kwargs.\r\n",
                "    \"\"\"\r\n",
                "    function = partial(fn, **kwargs)\r\n",
                "    if name is not None:\r\n",
                "        function.__name__ = name\r\n",
                "    return function"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "source": [
                "# Aggregation Functions\r\n",
                "\r\n",
                "\r\n",
                "def ewm(series: pd.Series, halflife: float = 10.0) -> pd.Series:\r\n",
                "    return series.ewm(halflife=halflife).mean().iat[-1]\r\n",
                "\r\n",
                "\r\n",
                "ewm10 = derive(ewm, \"ewm10\", halflife=10.0)\r\n",
                "ewm20 = derive(ewm, \"ewm20\", halflife=20.0)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "source": [
                "from collections import OrderedDict\r\n",
                "\r\n",
                "\r\n",
                "class CreateFeatures:\r\n",
                "    \"\"\"Class to compute features.\r\n",
                "\r\n",
                "    Args:\r\n",
                "        features: list[dict[str, (Callable, Callable)]]\r\n",
                "            Each key is the name of a feature.\r\n",
                "            Each value is a tuple: ``(fn, agg)`` where fn is a function applied to the book \r\n",
                "            to make series and agg is an aggregation function\r\n",
                "\r\n",
                "            If agg is not None:\r\n",
                "                feature (pd.Series) will be computed by 1) applying fn to a book,\r\n",
                "                2) aggregating the output by `time_id`, and then \r\n",
                "                3) aggregate the groupby object with agg.\r\n",
                "                fn receives pd.DataFrame of book and returns pd.Series of feature time-series.\r\n",
                "                agg is any aggregation function that can be passed to pd.SeriesGroupby.agg.\r\n",
                "\r\n",
                "            If agg is None:\r\n",
                "                feature will be computed by fn(book).\r\n",
                "    \"\"\"\r\n",
                "\r\n",
                "    def __init__(self, features: List[Tuple[Callable, Callable]]) -> None:\r\n",
                "        # attribute _features is:\r\n",
                "        # each key: name of feature \"{fn name}__{aggregation name}\"\r\n",
                "        # each value: (fn, agg) \r\n",
                "        self._features = OrderedDict()\r\n",
                "        for fn, agg in features:\r\n",
                "            name = self._feature_name(fn, agg)\r\n",
                "            self.register_feature(name, fn=fn, agg=agg)\r\n",
                "\r\n",
                "    def compute_df_features(self, book, trade) -> pd.DataFrame:\r\n",
                "        return pd.merge(\r\n",
                "                        pd.DataFrame(\r\n",
                "                        {\r\n",
                "                            name: self._compute_feature(book, fn, agg)\r\n",
                "                            for name, fn, agg in self.features()\r\n",
                "                            if not 'trade__' in name\r\n",
                "                        }\r\n",
                "                        ).reset_index(drop=True),\r\n",
                "                        pd.DataFrame(\r\n",
                "                        {\r\n",
                "                            name: self._compute_feature(trade, fn, agg)\r\n",
                "                            for name, fn, agg in self.features()\r\n",
                "                            if \"trade__\" in name or \"stock_id\" in name or \"time_id\" in name\r\n",
                "                        }\r\n",
                "                        ).reset_index(drop=True),\r\n",
                "                        on=[\"stock_id\", \"time_id\"],\r\n",
                "                        how=\"outer\"\r\n",
                "        )\r\n",
                "\r\n",
                "    def register_feature(self, name, fn, agg) -> None:\r\n",
                "        \"\"\"Adds a feature to the class.\"\"\"\r\n",
                "        self._features[name] = (fn, agg)\r\n",
                "        \r\n",
                "    def features(self) -> Iterable:\r\n",
                "        \"\"\"Returns an iterator over (name, fn, agg) of features.\"\"\"\r\n",
                "        for name, (fn, agg) in self._features.items():\r\n",
                "            yield (name, fn, agg)\r\n",
                "\r\n",
                "    @property\r\n",
                "    def feature_names(self) -> List[str]:\r\n",
                "        return list(self._features.keys())\r\n",
                "\r\n",
                "    def _feature_name(self, fn, agg) -> str:\r\n",
                "        name = fn.__name__\r\n",
                "        if agg is not None:\r\n",
                "            name += \"__\" + (agg if isinstance(agg, str) else agg.__name__)\r\n",
                "        return name\r\n",
                "\r\n",
                "    def _compute_feature(self, book_trade, fn, agg) -> pd.Series:\r\n",
                "        output = fn(book_trade)\r\n",
                "        if agg is not None:\r\n",
                "            output = output.groupby(book_trade.time_id).agg(agg)\r\n",
                "        return output"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "source": [
                "from itertools import product\r\n",
                "\r\n",
                "features = [\r\n",
                "    # book\r\n",
                "    (stock_id, None),\r\n",
                "    (time_id, None),\r\n",
                "    (instvar, np.mean),  # volatility\r\n",
                "    (instvar2, np.mean),  # volatility\r\n",
                "    (updown, None),\r\n",
                "    # trade\r\n",
                "    (trade__true_range, None),\r\n",
                "]\r\n",
                "\r\n",
                "\r\n",
                "fns = [\r\n",
                "    # book\r\n",
                "    price_spread1, price_spread2, price_spread_bid, price_spread_ask, size_total_bid, size_total_ask,\r\n",
                "    size_total1, size_total2, size_total3, size_spread1, size_spread2, size_spread3,\r\n",
                "    # trade\r\n",
                "    trade__size, trade__price, trade__order_count,\r\n",
                "    ]\r\n",
                "aggs = [np.mean, np.max, np.min, median_absolute_deviation, np.std, ewm10, ewm20]\r\n",
                "\r\n",
                "\r\n",
                "for fn, agg in product(fns, aggs):\r\n",
                "    features.append((fn, agg))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "source": [
                "cf = CreateFeatures(features)\r\n",
                "\r\n",
                "cf.feature_names"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "['stock_id',\n",
                            " 'time_id',\n",
                            " 'instvar__mean',\n",
                            " 'instvar2__mean',\n",
                            " 'updown',\n",
                            " 'trade__true_range',\n",
                            " 'price_spread1__mean',\n",
                            " 'price_spread1__amax',\n",
                            " 'price_spread1__amin',\n",
                            " 'price_spread1__median_absolute_deviation',\n",
                            " 'price_spread1__std',\n",
                            " 'price_spread1__ewm10',\n",
                            " 'price_spread1__ewm20',\n",
                            " 'price_spread2__mean',\n",
                            " 'price_spread2__amax',\n",
                            " 'price_spread2__amin',\n",
                            " 'price_spread2__median_absolute_deviation',\n",
                            " 'price_spread2__std',\n",
                            " 'price_spread2__ewm10',\n",
                            " 'price_spread2__ewm20',\n",
                            " 'price_spread_bid__mean',\n",
                            " 'price_spread_bid__amax',\n",
                            " 'price_spread_bid__amin',\n",
                            " 'price_spread_bid__median_absolute_deviation',\n",
                            " 'price_spread_bid__std',\n",
                            " 'price_spread_bid__ewm10',\n",
                            " 'price_spread_bid__ewm20',\n",
                            " 'price_spread_ask__mean',\n",
                            " 'price_spread_ask__amax',\n",
                            " 'price_spread_ask__amin',\n",
                            " 'price_spread_ask__median_absolute_deviation',\n",
                            " 'price_spread_ask__std',\n",
                            " 'price_spread_ask__ewm10',\n",
                            " 'price_spread_ask__ewm20',\n",
                            " 'size_total_bid__mean',\n",
                            " 'size_total_bid__amax',\n",
                            " 'size_total_bid__amin',\n",
                            " 'size_total_bid__median_absolute_deviation',\n",
                            " 'size_total_bid__std',\n",
                            " 'size_total_bid__ewm10',\n",
                            " 'size_total_bid__ewm20',\n",
                            " 'size_total_ask__mean',\n",
                            " 'size_total_ask__amax',\n",
                            " 'size_total_ask__amin',\n",
                            " 'size_total_ask__median_absolute_deviation',\n",
                            " 'size_total_ask__std',\n",
                            " 'size_total_ask__ewm10',\n",
                            " 'size_total_ask__ewm20',\n",
                            " 'size_total1__mean',\n",
                            " 'size_total1__amax',\n",
                            " 'size_total1__amin',\n",
                            " 'size_total1__median_absolute_deviation',\n",
                            " 'size_total1__std',\n",
                            " 'size_total1__ewm10',\n",
                            " 'size_total1__ewm20',\n",
                            " 'size_total2__mean',\n",
                            " 'size_total2__amax',\n",
                            " 'size_total2__amin',\n",
                            " 'size_total2__median_absolute_deviation',\n",
                            " 'size_total2__std',\n",
                            " 'size_total2__ewm10',\n",
                            " 'size_total2__ewm20',\n",
                            " 'size_total3__mean',\n",
                            " 'size_total3__amax',\n",
                            " 'size_total3__amin',\n",
                            " 'size_total3__median_absolute_deviation',\n",
                            " 'size_total3__std',\n",
                            " 'size_total3__ewm10',\n",
                            " 'size_total3__ewm20',\n",
                            " 'size_spread1__mean',\n",
                            " 'size_spread1__amax',\n",
                            " 'size_spread1__amin',\n",
                            " 'size_spread1__median_absolute_deviation',\n",
                            " 'size_spread1__std',\n",
                            " 'size_spread1__ewm10',\n",
                            " 'size_spread1__ewm20',\n",
                            " 'size_spread2__mean',\n",
                            " 'size_spread2__amax',\n",
                            " 'size_spread2__amin',\n",
                            " 'size_spread2__median_absolute_deviation',\n",
                            " 'size_spread2__std',\n",
                            " 'size_spread2__ewm10',\n",
                            " 'size_spread2__ewm20',\n",
                            " 'size_spread3__mean',\n",
                            " 'size_spread3__amax',\n",
                            " 'size_spread3__amin',\n",
                            " 'size_spread3__median_absolute_deviation',\n",
                            " 'size_spread3__std',\n",
                            " 'size_spread3__ewm10',\n",
                            " 'size_spread3__ewm20',\n",
                            " 'trade__size__mean',\n",
                            " 'trade__size__amax',\n",
                            " 'trade__size__amin',\n",
                            " 'trade__size__median_absolute_deviation',\n",
                            " 'trade__size__std',\n",
                            " 'trade__size__ewm10',\n",
                            " 'trade__size__ewm20',\n",
                            " 'trade__price__mean',\n",
                            " 'trade__price__amax',\n",
                            " 'trade__price__amin',\n",
                            " 'trade__price__median_absolute_deviation',\n",
                            " 'trade__price__std',\n",
                            " 'trade__price__ewm10',\n",
                            " 'trade__price__ewm20',\n",
                            " 'trade__order_count__mean',\n",
                            " 'trade__order_count__amax',\n",
                            " 'trade__order_count__amin',\n",
                            " 'trade__order_count__median_absolute_deviation',\n",
                            " 'trade__order_count__std',\n",
                            " 'trade__order_count__ewm10',\n",
                            " 'trade__order_count__ewm20']"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 9
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "source": [
                "def create_df_features(cf: CreateFeatures, train_test: str = None) -> pd.DataFrame:\r\n",
                "    paths = glob.glob(DATA_DIR + f\"book_{train_test}.parquet/*\")\r\n",
                "    dfs = []\r\n",
                "    for path in tqdm(paths):\r\n",
                "        book = pd.read_parquet(path)\r\n",
                "        trade = pd.read_parquet(path.replace('book', 'trade'))\r\n",
                "        book[\"stock_id\"] = trade[\"stock_id\"] = int(path.split(\"=\")[-1])\r\n",
                "        dfs.append(cf.compute_df_features(book, trade))\r\n",
                "    df_features = pd.concat(dfs).reset_index(drop=True)\r\n",
                "    return df_features"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "source": [
                "class Model(metaclass=ABCMeta):\r\n",
                "\r\n",
                "    def __init__(self, run_fold_name: str, feature_names: List[str],\r\n",
                "                 params: dict) -> None:\r\n",
                "        ''' Constructor\r\n",
                "\r\n",
                "        :param feature_names: list of feature names to specify columns of feature dataframe\r\n",
                "        :param params: hyper parameters\r\n",
                "        '''\r\n",
                "        self.run_fold_name = run_fold_name\r\n",
                "        self.feature_names = feature_names\r\n",
                "        self.params = params\r\n",
                "        self.model = None\r\n",
                "\r\n",
                "    @abstractmethod\r\n",
                "    def train(self, X_train: pd.DataFrame, y_train: pd.Series,\r\n",
                "              X_valid: Optional[pd.DataFrame] = None,\r\n",
                "              y_valid: Optional[pd.Series] = None\r\n",
                "              ) -> None:\r\n",
                "        ''' trains a model\r\n",
                "\r\n",
                "        :param X_train: features of training data\r\n",
                "        :param y_train: targets of training data\r\n",
                "        :param X_valid: features of validation data\r\n",
                "        :param y_valid: targets of validation data\r\n",
                "        '''\r\n",
                "        pass\r\n",
                "\r\n",
                "    @abstractmethod\r\n",
                "    def predict(self, X: pd.DataFrame) -> np.array:\r\n",
                "        ''' returns prediction output from a learned model\r\n",
                "\r\n",
                "        :param X: features of test data or validation data\r\n",
                "        :return: predicted value\r\n",
                "        '''\r\n",
                "        pass\r\n",
                "\r\n",
                "    @abstractmethod\r\n",
                "    def save_model(self) -> None:\r\n",
                "        ''' saves a model '''\r\n",
                "        pass\r\n",
                "\r\n",
                "    @abstractmethod\r\n",
                "    def load_model(self) -> None:\r\n",
                "        ''' loads a model '''\r\n",
                "        pass"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "source": [
                "class ModelLGB(Model):\r\n",
                "\r\n",
                "\r\n",
                "    def train(self, X_train, y_train, X_valid=None, y_valid=None):\r\n",
                "\r\n",
                "        params = self.params\r\n",
                "        if X_valid is not None:\r\n",
                "            # weights to change feval from RMSE to RMSPE\r\n",
                "            # idea from: https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/250324\r\n",
                "            w_train = 1/np.square(y_train)\r\n",
                "            w_valid = 1/np.square(y_valid)\r\n",
                "            lgb_train = lgb.Dataset(X_train, y_train, weight=w_train)\r\n",
                "            lgb_eval = lgb.Dataset(X_valid, y_valid, weight=w_valid)\r\n",
                "            self.model = lgb.train(params,\r\n",
                "                                   lgb_train,\r\n",
                "                                   num_boost_round=100,\r\n",
                "                                   valid_sets=lgb_eval,\r\n",
                "                                   feval=rmspe,\r\n",
                "                                   verbose_eval=50,\r\n",
                "                                   early_stopping_rounds=100,\r\n",
                "                                   categorical_feature=['stock_id']\r\n",
                "                                  )\r\n",
                "        else:\r\n",
                "            w_train = 1/np.square(y_train)\r\n",
                "            lgb_train = lgb.Dataset(X_train, y_train, weight=w_train)\r\n",
                "            self.model = lgb.train(params,\r\n",
                "                                   lgb_train,\r\n",
                "                                   num_boost_round=100,\r\n",
                "                                   feval=rmspe,\r\n",
                "                                   categorical_feature=['stock_id']\r\n",
                "                           )\r\n",
                "\r\n",
                "    def predict(self, X_test):\r\n",
                "        return self.model.predict(X_test)\r\n",
                "\r\n",
                "    def save_model(self):\r\n",
                "        self.model.save_model('model.txt')\r\n",
                "\r\n",
                "    def load_model(self):\r\n",
                "        self.model = lgb.Booster(model_file='model.txt')"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "source": [
                "# delf-defiend evaluation metric function\r\n",
                "def rmspe(y_true: np.array, y_pred: np.array):\r\n",
                "    ''' self-defined eval metric\r\n",
                "        Root Mean Squared Percentage Error\r\n",
                "\r\n",
                "    :return: name: str, eval_result: float, is_higher_better: bool\r\n",
                "    '''\r\n",
                "    if type(y_pred) == lgb.basic.Dataset:\r\n",
                "        y_pred = y_pred.get_label()\r\n",
                "    rmspe = (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true))))\r\n",
                "    return 'RMSPE', rmspe, False"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "source": [
                "class Util:\r\n",
                "    @classmethod\r\n",
                "    def dump(cls, value, path):\r\n",
                "        os.makedirs(os.path.dirname(path), exist_ok=True)\r\n",
                "        joblib.dump(value, path, compress=True)\r\n",
                "\r\n",
                "    @classmethod\r\n",
                "    def load(cls, path):\r\n",
                "        return joblib.load(path)\r\n",
                "\r\n",
                "    @classmethod\r\n",
                "    def submission(cls, df_pred: pd.DataFrame) -> None:\r\n",
                "        row_id = df_pred['stock_id'].apply(str) + '-' + df_pred['time_id'].apply(str)\r\n",
                "        df_submission = pd.DataFrame({'row_id': row_id, 'target':df_pred['target']})\r\n",
                "        df_submission.to_csv('submission.csv', index=False)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "source": [
                "class Runner:\r\n",
                "\r\n",
                "    def __init__(self, run_name: str, model_cls: Callable[[str, dict], Model],\r\n",
                "                 feature_names: List[str], df_features_train: pd.DataFrame,\r\n",
                "                 df_features_test: pd.DataFrame, params: dict):\r\n",
                "        ''' Constructor\r\n",
                "\r\n",
                "        :param run_name: name of run\r\n",
                "        :param model_cls: class of model\r\n",
                "        :param feature_names: list of feature names\r\n",
                "        :param params: hyper parameters\r\n",
                "        '''\r\n",
                "        self.run_name = run_name\r\n",
                "        self.model_cls = model_cls\r\n",
                "        self.feature_names = feature_names\r\n",
                "        self.X_train_all = df_features_train\r\n",
                "        self.X_test = df_features_test\r\n",
                "        self.params = params\r\n",
                "        self.n_fold = 4\r\n",
                "\r\n",
                "    def _train_fold(self, i_fold: Union[int, str]) -> Tuple[\r\n",
                "                    Model, Optional[np.array],\r\n",
                "                    Optional[np.array], Optional[float]]:\r\n",
                "        ''' specifies number of fold for cv then learns & evaluates\r\n",
                "\r\n",
                "        :param i_fold: number of fold ('all' for all)\r\n",
                "        :return: a tuple of instance of model, index of record,\r\n",
                "                 predicted value, and evaluation score\r\n",
                "                 (returns only model if i_fold=='all')\r\n",
                "        '''\r\n",
                "        # load train data\r\n",
                "        y_train_all = self._load_y_train()\r\n",
                "        self.X_train_all['stock_id'] = self.X_train_all['stock_id'].astype('int64')\r\n",
                "        self.X_train_all['time_id'] = self.X_train_all['time_id'].astype('int64')\r\n",
                "        Xy_train_all = pd.merge(self.X_train_all, y_train_all,\r\n",
                "                                left_on=['stock_id','time_id'], right_on=['stock_id','time_id'],\r\n",
                "                                how='inner')\r\n",
                "        X_train_all = Xy_train_all[self.feature_names]\r\n",
                "        y_train_all = Xy_train_all['target']\r\n",
                "\r\n",
                "        validation = i_fold != 'all'\r\n",
                "        if validation:\r\n",
                "            # split data into training and validation\r\n",
                "            idx_train, idx_valid = self._load_index_fold(i_fold)\r\n",
                "            X_train = X_train_all.iloc[idx_train]\r\n",
                "            y_train = y_train_all.iloc[idx_train]\r\n",
                "            X_valid = X_train_all.iloc[idx_valid]\r\n",
                "            y_valid = y_train_all.iloc[idx_valid]\r\n",
                "\r\n",
                "            # execute learning\r\n",
                "            model = self._build_model(i_fold)\r\n",
                "            model.train(X_train, y_train, X_valid, y_valid)\r\n",
                "\r\n",
                "            # prediction and evaluation with validation data\r\n",
                "            pred_valid = model.predict(X_valid)\r\n",
                "            _, score, _ = rmspe(y_true=y_valid, y_pred=pred_valid)\r\n",
                "\r\n",
                "            # return model, index, prediction, and score\r\n",
                "            return model, idx_valid, pred_valid, score\r\n",
                "        else:\r\n",
                "            # learining with all data\r\n",
                "            model = self._build_model(i_fold)\r\n",
                "            model.train(X_train_all, y_train_all)\r\n",
                "\r\n",
                "            # return model\r\n",
                "            return model, None, None, None\r\n",
                "\r\n",
                "    def run_train_cv(self) -> None:\r\n",
                "        ''' learns and evaluates by CV\r\n",
                "\r\n",
                "        learns, evaluates, and saves models and scores of each fold\r\n",
                "        '''\r\n",
                "        scores = []\r\n",
                "        idxes_valid = []\r\n",
                "        preds = []\r\n",
                "\r\n",
                "        # learning for each fold\r\n",
                "        for i_fold in range(self.n_fold):\r\n",
                "            model, idx_valid, pred_valid, score = self._train_fold(i_fold)\r\n",
                "\r\n",
                "            # hold result\r\n",
                "            idxes_valid.append(idx_valid)\r\n",
                "            scores.append(score)\r\n",
                "            preds.append(pred_valid)\r\n",
                "\r\n",
                "            # save model\r\n",
                "            model.save_model()\r\n",
                "        print(f'Mean score of the folds: {np.mean(scores)}')\r\n",
                "\r\n",
                "    def run_predict_cv(self) -> pd.DataFrame:\r\n",
                "        ''' predicts for test data with the mean of\r\n",
                "            each fold's model learned through CV\r\n",
                "            \r\n",
                "            :return: predicted target as the mean of folds\r\n",
                "        '''\r\n",
                "        preds = []\r\n",
                "        # prediction for each fold's model\r\n",
                "        for i_fold in range(self.n_fold):\r\n",
                "            model = self._build_model(i_fold)\r\n",
                "            model.load_model()\r\n",
                "            pred = model.predict(self.X_test[self.feature_names])\r\n",
                "            preds.append(pred)\r\n",
                "\r\n",
                "        # mean of the prediction values\r\n",
                "        pred_mean = np.mean(preds, axis=0)\r\n",
                "        df_pred = self.X_test[self.X_test.columns[:2]]\r\n",
                "        df_pred.loc[:, 'target'] = pred_mean\r\n",
                "        return df_pred\r\n",
                "\r\n",
                "    def run_train_all(self) -> None:\r\n",
                "        ''' learns with all the training data and save the model '''\r\n",
                "        # learning\r\n",
                "        i_fold = 'all'\r\n",
                "        model, _, _, _ = self._train_fold(i_fold)\r\n",
                "        model.save_model()\r\n",
                "\r\n",
                "    def run_predict_all(self) -> pd.DataFrame:\r\n",
                "        ''' predicts for test data with the model learned with all the training data\r\n",
                "\r\n",
                "        :return: predicted target\r\n",
                "        '''\r\n",
                "        \r\n",
                "        # predict with the mdoel learned with all the learning data\r\n",
                "        i_fold = 'all'\r\n",
                "        model = self._build_model(i_fold)\r\n",
                "        model.load_model()\r\n",
                "        pred = model.predict(self.X_test[self.feature_names])\r\n",
                "        df_pred = self.X_test[self.X_test.columns[:2]]\r\n",
                "        df_pred['target'] = pred\r\n",
                "        return df_pred\r\n",
                "\r\n",
                "    def _build_model(self, i_fold: Union[int, str]) -> Model:\r\n",
                "        ''' builds a model with a specified fold for cv\r\n",
                "\r\n",
                "        :param i_fold: number of fold\r\n",
                "        :return: instance of model\r\n",
                "        '''\r\n",
                "        # build a model with run name, fold, and class of model\r\n",
                "        run_fold_name = f'{self.run_name}-{i_fold}'\r\n",
                "        return self.model_cls(run_fold_name, self.feature_names, self.params)\r\n",
                "\r\n",
                "    def _load_y_train(self) -> pd.DataFrame:\r\n",
                "        ''' loads target of train data; ['stock_id', 'time_id', 'target']\r\n",
                "\r\n",
                "        :return: target dataframe of train data\r\n",
                "        '''\r\n",
                "        return pd.read_csv(DATA_DIR + 'train.csv')\r\n",
                "\r\n",
                "    def _load_index_fold(self, i_fold: int) -> np.array:\r\n",
                "        ''' returns the record index in response to the fold specified for cv\r\n",
                "\r\n",
                "        :param i_fold: number of the fold\r\n",
                "        :return: record index for the fold\r\n",
                "        '''\r\n",
                "        # return index to split data for learning and validation\r\n",
                "        y_train = self._load_y_train()\r\n",
                "        x_dummy = np.zeros(len(y_train))\r\n",
                "        skf = KFold(n_splits=self.n_fold, shuffle=True, random_state=31)\r\n",
                "        return list(skf.split(x_dummy, y_train))[i_fold]"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## main"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "source": [
                "params_lgb = {\r\n",
                "            'boosting_type': 'gbdt',\r\n",
                "            'num_leaves': 100,\r\n",
                "            'learning_rate': 0.05,\r\n",
                "            'n_estimators': 1000,\r\n",
                "            'metric': 'rmse',\r\n",
                "            }\r\n",
                "\r\n",
                "# rerun=False if just using saved features works\r\n",
                "# cf = CreateFeatures(rerun=True)\r\n",
                "df_features_train = create_df_features(cf, \"train\")\r\n",
                "df_features_test = create_df_features(cf, \"test\")\r\n",
                "print(df_features_train.head())\r\n",
                "feature_names = cf.feature_names\r\n",
                "\r\n",
                "# learning and prediction by LightGBM and create submission file\r\n",
                "run_name = 'lgb'\r\n",
                "runner = Runner(run_name=run_name,\r\n",
                "                model_cls=ModelLGB,\r\n",
                "                feature_names=feature_names,\r\n",
                "                df_features_train=df_features_train,\r\n",
                "                df_features_test=df_features_test,\r\n",
                "                params=params_lgb)\r\n",
                "runner.run_train_all()\r\n",
                "pred = runner.run_predict_all()\r\n",
                "Util.submission(pred)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        " 18%|█▊        | 20/112 [16:45<1:18:18, 51.07s/it]"
                    ]
                }
            ],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.8.8",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.8.8 64-bit ('optiver-env': conda)"
        },
        "interpreter": {
            "hash": "123ef78029e45cba9d6951e4ccbdaba0b0d99d8cf41cf61f7566ca31b4f1d296"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}